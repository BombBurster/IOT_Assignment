{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "import ipynb\n",
    "from ipynb.fs.full.Data_prep import *\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "TIME_PERIODS = 200\n",
    "STEP_DISTANCE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2959, 200, 6)\n",
      "(11562, 200, 6)\n"
     ]
    }
   ],
   "source": [
    "#Normalize before and After\n",
    "\n",
    "# dataset = pd.read_csv('watch.csv')\n",
    "# # print(dataset)\n",
    "# column_names = dataset.keys()\n",
    "# Dataset = normalize(dataset, axis=0)\n",
    "# Dataset = pd.DataFrame(Dataset, columns=column_names)\n",
    "# Dataset['user-id'] = dataset['user-id']\n",
    "# Dataset['timestamp'] = dataset['timestamp']\n",
    "# Dataset['activity'] = dataset['activity']\n",
    "# # print(Dataset)\n",
    "# test, train = split_test_train(Dataset, 'user-id', 0.8)\n",
    "# # print(test.shape)\n",
    "# # print(train.shape)\n",
    "# x_train, y_train = segment(train, TIME_PERIODS, STEP_DISTANCE, 'activity', train.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "# x_test, y_test = segment(test, TIME_PERIODS, STEP_DISTANCE, 'activity', test.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "# # print(x_train.shape, y_train.shape)\n",
    "# # print(x_test.shape, y_test.shape)\n",
    "# x_test_n = change_segments(x_test)\n",
    "# x_train_n = change_segments(x_train)\n",
    "# # print(x_test_n)\n",
    "# # print(x_train_n)\n",
    "# # print(x_test_n.shape, ',', y_test.shape)\n",
    "# # print(x_train_n.shape, ',', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000 0.0000 2.0000 ... 4.1304 0.0008 0.0006]\n",
      " [3.0000 10.0000 23.0000 ... 4.2391 0.0008 0.0007]\n",
      " [5.0000 32.0000 25.0000 ... 4.0889 0.0007 0.0006]\n",
      " ...\n",
      " [1.0000 0.0000 1.0000 ... 4.5581 0.0000 0.0000]\n",
      " [1.0000 0.0000 4.0000 ... 4.4545 0.0001 0.0001]\n",
      " [1.0000 0.0000 1.0000 ... 4.6190 0.0001 0.0001]]\n"
     ]
    }
   ],
   "source": [
    "# with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "#     print(x_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3664 -0.6650 -0.8355 ... -0.5030 0.8776 0.9710]\n",
      " [-0.2273 -0.0043 0.2214 ... -0.4464 0.9016 1.0675]\n",
      " [-0.0882 1.4490 0.3220 ... -0.5247 0.7920 0.9037]\n",
      " ...\n",
      " [-0.3664 -0.6650 -0.8859 ... -0.2801 -0.5031 -0.4815]\n",
      " [-0.3664 -0.6650 -0.7349 ... -0.3341 -0.3753 -0.3395]\n",
      " [-0.3664 -0.6650 -0.8859 ... -0.2484 -0.2961 -0.2790]]\n"
     ]
    }
   ],
   "source": [
    "# # transformer = Normalizer().fit(x_train_n)\n",
    "# transformer = StandardScaler().fit(x_train_n)\n",
    "# x_train_n = transformer.transform(x_train_n)\n",
    "# x_test_n = transformer.transform(x_test_n)\n",
    "# with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "#     print(x_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21561338289962825\n"
     ]
    }
   ],
   "source": [
    "# param_grid_in = [\n",
    "# #             {'C': [0.01, 0.001, 0.0001],\n",
    "# #              'tol': [1, 0.01, 0.001, 0.0001],\n",
    "# #              'max_iter': [-1, 1000, 5000],\n",
    "#              {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#              'degree': [2], #,3\n",
    "#              'class_weight': ['balanced']}\n",
    "# #              'gamma': [1, 0.1, 0.001, 0.0001, 0.00001],\n",
    "# #              'decision_function_shape': ['ovo', 'ovr'],  # one-vs-one/one-vs-rest\n",
    "# #              'class_weight': ['balanced']}  # auto balance the weight\n",
    "#         ]\n",
    "# clf = SVC()\n",
    "# svm_model = GridSearchCV(clf, param_grid=param_grid_in, cv=10, n_jobs=4, error_score=np.nan, verbose=0) \n",
    "# svm_model = svm_model.fit(x_train_n, y_train)\n",
    "# y_pred = svm_model.predict(x_test_n)\n",
    "# acc = metrics.accuracy_score(y_test, y_pred, normalize=True)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weight option: None\n",
      "Best kernel: rbf\n",
      "Best polynomial degree: 2\n",
      "Best gamma: auto_deprecated\n",
      "Best C: 1.0\n",
      "Best tolerance: 0.001\n",
      "Best max number of iterations -1\n",
      "Best decision function shape option ovr \n",
      "\n",
      "The accuracy score is:  0.21561338289962825\n",
      "The balanced accuracy score is:  0.22347320825903422\n"
     ]
    }
   ],
   "source": [
    "# # train the model and time the training\n",
    "# #     start_time = time.time()\n",
    "# #     svm_model = svm_model.fit(x_train_in, y_train_in)\n",
    "# #     end_time = time.time()\n",
    "\n",
    "# # print time for training\n",
    "# # print('\\nTraining takes ', end_time - start_time, 's\\n')\n",
    "\n",
    "# # print the best hyper-parameters\n",
    "# print('\\nClass weight option:', svm_model.best_estimator_.get_params()['class_weight'])\n",
    "# print('Best kernel:', svm_model.best_estimator_.get_params()['kernel'])\n",
    "# print('Best polynomial degree:', svm_model.best_estimator_.get_params()['degree'])\n",
    "# print('Best gamma:', svm_model.best_estimator_.get_params()['gamma'])\n",
    "# print('Best C:', svm_model.best_estimator_.get_params()['C'])\n",
    "# print('Best tolerance:', svm_model.best_estimator_.get_params()['tol'])\n",
    "# print('Best max number of iterations', svm_model.best_estimator_.get_params()['max_iter'])\n",
    "# print('Best decision function shape option', svm_model.best_estimator_.get_params()['decision_function_shape'],\n",
    "#       '\\n')\n",
    "\n",
    "# # print the accuracy scores\n",
    "# y_pred = svm_model.predict(x_test_n)\n",
    "# result = metrics.accuracy_score(y_test, y_pred)\n",
    "# result_2 = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "# print('The accuracy score is: ', result)\n",
    "# print('The balanced accuracy score is: ', result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(645031,)\n",
      "(645031, 8)\n",
      "[[-1.2587 -0.4021 -0.8431 ... -0.9908 0.3575 1.2601]\n",
      " [-1.2587 -0.4021 -0.0951 ... -1.0163 0.0299 0.2306]\n",
      " [-1.2587 -0.4021 0.2563 ... -0.8358 0.4636 -0.4004]\n",
      " ...\n",
      " [1.6057 0.9805 -0.0977 ... -0.0550 0.4516 -0.2037]\n",
      " [1.6057 0.9805 -0.1637 ... -0.1295 0.3761 -0.1525]\n",
      " [1.6057 0.9805 -0.1119 ... -0.1717 0.2225 -0.0244]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a291213ce4dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Give in the raw data\n",
    "\n",
    "# dataset = pd.read_csv('phone.csv')\n",
    "# column_names = dataset.keys()\n",
    "# test, train = split_test_train(dataset, 'user-id', 0.8)\n",
    "# y_test = test['activity'].to_numpy().T.astype(float)\n",
    "# x_test = test.drop(columns=['activity'])\n",
    "# y_train = test['activity'].to_numpy().T.astype(float)\n",
    "# print(y_train.shape)\n",
    "# x_train = test.drop(columns=['activity'])\n",
    "# transformer = StandardScaler().fit(x_train)\n",
    "# x_train_n = transformer.transform(x_train)\n",
    "# x_test_n = transformer.transform(x_test)\n",
    "# print(x_train_n.shape)\n",
    "# with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "#     print(x_test_n)\n",
    "# param_grid_in = [\n",
    "# #             {'C': [0.01, 0.001, 0.0001],\n",
    "# #              'tol': [1, 0.01, 0.001, 0.0001],\n",
    "# #              'max_iter': [-1, 1000, 5000],\n",
    "#              {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#              'degree': [2], # ,3\n",
    "#              'class_weight': ['balanced']}\n",
    "# #              'gamma': [1, 0.1, 0.001, 0.0001, 0.00001],\n",
    "# #              'decision_function_shape': ['ovo', 'ovr'],  # one-vs-one/one-vs-rest\n",
    "# #              'class_weight': ['balanced']}  # auto balance the weight\n",
    "#         ]\n",
    "# clf = SVC()\n",
    "# svm_model = GridSearchCV(clf, param_grid=param_grid_in, cv=10, n_jobs=4, error_score=np.nan, verbose=0) \n",
    "# svm_model = svm_model.fit(x_train_n, y_train)\n",
    "# y_pred = svm_model.predict(x_test_n)\n",
    "# acc = metrics.accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model and time the training\n",
    "# #     start_time = time.time()\n",
    "# #     svm_model = svm_model.fit(x_train_in, y_train_in)\n",
    "# #     end_time = time.time()\n",
    "\n",
    "#     # print time for training\n",
    "#     print('\\nTraining takes ', end_time - start_time, 's\\n')\n",
    "\n",
    "#     # print the best hyper-parameters\n",
    "#     print('\\nClass weight option:', svm_model.best_estimator_.get_params()['class_weight'])\n",
    "#     print('Best kernel:', svm_model.best_estimator_.get_params()['kernel'])\n",
    "#     print('Best polynomial degree:', svm_model.best_estimator_.get_params()['degree'])\n",
    "#     print('Best gamma:', svm_model.best_estimator_.get_params()['gamma'])\n",
    "#     print('Best C:', svm_model.best_estimator_.get_params()['C'])\n",
    "#     print('Best tolerance:', svm_model.best_estimator_.get_params()['tol'])\n",
    "#     print('Best max number of iterations', svm_model.best_estimator_.get_params()['max_iter'])\n",
    "#     print('Best decision function shape option', svm_model.best_estimator_.get_params()['decision_function_shape'],\n",
    "#           '\\n')\n",
    "\n",
    "#     # print the accuracy scores\n",
    "#     y_pred = svm_model.predict(x_test_in)\n",
    "#     result = metrics.accuracy_score(y_test_in, y_pred)\n",
    "#     result_2 = metrics.balanced_accuracy_score(y_test_in, y_pred)\n",
    "#     print('The accuracy score is: ', result)\n",
    "#     print('The balanced accuracy score is: ', result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 200, 6)\n",
      "(13542, 200, 6)\n"
     ]
    }
   ],
   "source": [
    "#Normalizer or Standard Scaler only after feature extraction\n",
    "\n",
    "dataset = pd.read_csv('watch.csv')\n",
    "# print(dataset)\n",
    "column_names = dataset.keys()\n",
    "# Dataset = normalize(dataset, axis=0)\n",
    "# Dataset = pd.DataFrame(Dataset, columns=column_names)\n",
    "# Dataset['user-id'] = dataset['user-id']\n",
    "# Dataset['timestamp'] = dataset['timestamp']\n",
    "# Dataset['activity'] = dataset['activity']\n",
    "# print(Dataset)\n",
    "test, train = split_test_train(dataset, 'user-id', 0.8)\n",
    "# print(test.shape)\n",
    "# print(train.shape)\n",
    "x_train, y_train = segment(train, TIME_PERIODS, STEP_DISTANCE, 'activity', train.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "x_test, y_test = segment(test, TIME_PERIODS, STEP_DISTANCE, 'activity', test.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)\n",
    "x_test_n = change_segments(x_test)\n",
    "x_train_n = change_segments(x_train)\n",
    "# print(x_test_n)\n",
    "# print(x_train_n)\n",
    "# print(x_test_n.shape, ',', y_test.shape)\n",
    "# print(x_train_n.shape, ',', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0390 0.0000 0.0146 ... 0.0456 0.0078 0.0063]\n",
      " [0.1089 0.2015 0.1307 ... 0.0473 0.0078 0.0064]\n",
      " [0.0183 0.0319 0.0958 ... 0.0388 0.0068 0.0055]\n",
      " ...\n",
      " [0.0039 0.0237 0.1261 ... 0.0195 0.0079 0.0046]\n",
      " [0.0661 0.0623 0.1128 ... 0.0258 0.0071 0.0045]\n",
      " [0.0209 0.0585 0.1754 ... 0.0237 0.0044 0.0030]]\n"
     ]
    }
   ],
   "source": [
    "transformer = Normalizer().fit(x_train_n) # Normalization = 0.49\n",
    "# transformer = StandardScaler().fit(x_train_n) # StandardScaler = 0.7%\n",
    "x_train_n = transformer.transform(x_train_n)\n",
    "x_test_n = transformer.transform(x_test_n)\n",
    "with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "    print(x_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4978645515558267\n"
     ]
    }
   ],
   "source": [
    "param_grid_in = [\n",
    "#             {'C': [0.01, 0.001, 0.0001],\n",
    "#              'tol': [1, 0.01, 0.001, 0.0001],\n",
    "#              'max_iter': [-1, 1000, 5000],\n",
    "             {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'degree': [2], # ,3\n",
    "             'class_weight': ['balanced']}\n",
    "#              'gamma': [1, 0.1, 0.001, 0.0001, 0.00001],\n",
    "#              'decision_function_shape': ['ovo', 'ovr'],  # one-vs-one/one-vs-rest\n",
    "#              'class_weight': ['balanced']}  # auto balance the weight\n",
    "        ]\n",
    "clf = SVC()\n",
    "svm_model = GridSearchCV(clf, param_grid=param_grid_in, cv=10, n_jobs=4, error_score=np.nan, verbose=0) \n",
    "svm_model = svm_model.fit(x_train_n, y_train)\n",
    "y_pred = svm_model.predict(x_test_n)\n",
    "acc = metrics.accuracy_score(y_test, y_pred, normalize=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weight option: balanced\n",
      "Best kernel: linear\n",
      "Best polynomial degree: 2\n",
      "Best gamma: auto_deprecated\n",
      "Best C: 1.0\n",
      "Best tolerance: 0.001\n",
      "Best max number of iterations -1\n",
      "Best decision function shape option ovr \n",
      "\n",
      "The accuracy score is:  0.4978645515558267\n",
      "The balanced accuracy score is:  0.4987370163787962\n"
     ]
    }
   ],
   "source": [
    "# train the model and time the training\n",
    "#     start_time = time.time()\n",
    "#     svm_model = svm_model.fit(x_train_in, y_train_in)\n",
    "#     end_time = time.time()\n",
    "\n",
    "# print time for training\n",
    "# print('\\nTraining takes ', end_time - start_time, 's\\n')\n",
    "\n",
    "# print the best hyper-parameters\n",
    "print('\\nClass weight option:', svm_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best kernel:', svm_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best polynomial degree:', svm_model.best_estimator_.get_params()['degree'])\n",
    "print('Best gamma:', svm_model.best_estimator_.get_params()['gamma'])\n",
    "print('Best C:', svm_model.best_estimator_.get_params()['C'])\n",
    "print('Best tolerance:', svm_model.best_estimator_.get_params()['tol'])\n",
    "print('Best max number of iterations', svm_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best decision function shape option', svm_model.best_estimator_.get_params()['decision_function_shape'],\n",
    "      '\\n')\n",
    "\n",
    "# print the accuracy scores\n",
    "y_pred = svm_model.predict(x_test_n)\n",
    "result = metrics.accuracy_score(y_test, y_pred)\n",
    "result_2 = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "print('The accuracy score is: ', result)\n",
    "print('The balanced accuracy score is: ', result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2588, 200, 6)\n",
      "(14232, 200, 6)\n"
     ]
    }
   ],
   "source": [
    "#MinMax\n",
    "\n",
    "dataset = pd.read_csv('watch.csv')\n",
    "# print(dataset)\n",
    "column_names = dataset.keys()\n",
    "# Dataset = normalize(dataset, axis=0)\n",
    "# Dataset = pd.DataFrame(Dataset, columns=column_names)\n",
    "# Dataset['user-id'] = dataset['user-id']\n",
    "# Dataset['timestamp'] = dataset['timestamp']\n",
    "# Dataset['activity'] = dataset['activity']\n",
    "# print(Dataset)\n",
    "test, train = split_test_train(dataset, 'user-id', 0.8)\n",
    "# print(test.shape)\n",
    "# print(train.shape)\n",
    "x_train, y_train = segment(train, TIME_PERIODS, STEP_DISTANCE, 'activity', train.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "x_test, y_test = segment(test, TIME_PERIODS, STEP_DISTANCE, 'activity', test.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)\n",
    "x_test_n = change_segments(x_test)\n",
    "x_train_n = change_segments(x_train)\n",
    "# print(x_test_n)\n",
    "# print(x_train_n)\n",
    "# print(x_test_n.shape, ',', y_test.shape)\n",
    "# print(x_train_n.shape, ',', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0510 0.0585 0.0471 ... 0.0381 0.3039 0.2582]\n",
      " [0.0255 0.0319 0.1152 ... 0.0593 0.2651 0.2444]\n",
      " [0.0000 0.0638 0.2042 ... 0.0731 0.3219 0.3131]\n",
      " ...\n",
      " [0.0000 0.1489 0.1309 ... 0.0313 0.2366 0.1863]\n",
      " [0.0510 0.0691 0.0366 ... 0.0355 0.2081 0.1762]\n",
      " [0.1173 0.1649 0.0733 ... 0.0352 0.3017 0.2212]]\n"
     ]
    }
   ],
   "source": [
    "transformer = preprocessing.MinMaxScaler().fit(x_train_n) #MinMax = 0.65%\n",
    "x_train_n = transformer.transform(x_train_n)\n",
    "x_test_n = transformer.transform(x_test_n)\n",
    "with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "    print(x_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weight option: balanced\n",
      "Best kernel: linear\n",
      "Best polynomial degree: 2\n",
      "Best gamma: auto_deprecated\n",
      "Best C: 1.0\n",
      "Best tolerance: 0.001\n",
      "Best max number of iterations -1\n",
      "Best decision function shape option ovr \n",
      "\n",
      "The accuracy score is:  0.64258114374034\n",
      "The balanced accuracy score is:  0.6457466664446995\n"
     ]
    }
   ],
   "source": [
    "param_grid_in = [\n",
    "#             {'C': [0.01, 0.001, 0.0001],\n",
    "#              'tol': [1, 0.01, 0.001, 0.0001],\n",
    "#              'max_iter': [-1, 1000, 5000],\n",
    "             {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'degree': [2], # ,3\n",
    "             'class_weight': ['balanced']}\n",
    "#              'gamma': [1, 0.1, 0.001, 0.0001, 0.00001],\n",
    "#              'decision_function_shape': ['ovo', 'ovr'],  # one-vs-one/one-vs-rest\n",
    "#              'class_weight': ['balanced']}  # auto balance the weight\n",
    "        ]\n",
    "clf = SVC()\n",
    "svm_model = GridSearchCV(clf, param_grid=param_grid_in, cv=10, n_jobs=4, error_score=np.nan, verbose=0) \n",
    "svm_model = svm_model.fit(x_train_n, y_train)\n",
    "# train the model and time the training\n",
    "#     start_time = time.time()\n",
    "#     svm_model = svm_model.fit(x_train_in, y_train_in)\n",
    "#     end_time = time.time()\n",
    "\n",
    "# print time for training\n",
    "# print('\\nTraining takes ', end_time - start_time, 's\\n')\n",
    "\n",
    "# print the best hyper-parameters\n",
    "print('\\nClass weight option:', svm_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best kernel:', svm_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best polynomial degree:', svm_model.best_estimator_.get_params()['degree'])\n",
    "print('Best gamma:', svm_model.best_estimator_.get_params()['gamma'])\n",
    "print('Best C:', svm_model.best_estimator_.get_params()['C'])\n",
    "print('Best tolerance:', svm_model.best_estimator_.get_params()['tol'])\n",
    "print('Best max number of iterations', svm_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best decision function shape option', svm_model.best_estimator_.get_params()['decision_function_shape'],\n",
    "      '\\n')\n",
    "\n",
    "# print the accuracy scores\n",
    "y_pred = svm_model.predict(x_test_n)\n",
    "result = metrics.accuracy_score(y_test, y_pred)\n",
    "result_2 = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "print('The accuracy score is: ', result)\n",
    "print('The balanced accuracy score is: ', result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_pearson(data, thresh):\n",
    "    corr = data.corr()\n",
    "    columns_to_remove = []\n",
    "#     print(corr)\n",
    "#     sns.heatmap(corr)\n",
    "    columns = data.keys()# np.full((corr.shape[0],), True, dtype=bool)\n",
    "#     print(columns)\n",
    "#     print(corr.shape)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i+1, corr.shape[0]):\n",
    "#             print(corr.iloc[i,j])\n",
    "            if abs(corr.iloc[i,j]) >= thresh:\n",
    "#                 print(j)\n",
    "#                 np.delete(columns,j)\n",
    "                columns_to_remove.append(j)\n",
    "#                 print(j)\n",
    "#                 if columns[j]:\n",
    "#                     print('here')\n",
    "#                     columns[j] = False\n",
    "    columns_to_remove = np.array(columns_to_remove)\n",
    "    columns_to_remove = np.unique(columns_to_remove)\n",
    "#     selected_columns = data.columns[columns]\n",
    "#     print(columns)\n",
    "#     data = data[selected_columns]\n",
    "    return columns_to_remove\n",
    "\n",
    "def p_value(x, y, cutoff):\n",
    "    columns_to_remove = []\n",
    "    columns = x.keys()\n",
    "    num_features = len(columns)\n",
    "    raw_scores, p_values = f_regression(x, y)\n",
    "    for i in range(num_features):\n",
    "        if (p_values[i] > cutoff):\n",
    "            columns_to_remove.append(i)\n",
    "    columns_to_remove = np.array(columns_to_remove)\n",
    "    columns_to_remove = np.unique(columns_to_remove)\n",
    "    return columns_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 200, 6)\n",
      "(13821, 200, 6)\n"
     ]
    }
   ],
   "source": [
    "# Using pearson Correlation feature selection\n",
    "\n",
    "dataset = pd.read_csv('watch.csv')\n",
    "# print(dataset)\n",
    "column_names = dataset.keys()\n",
    "# Dataset = normalize(dataset, axis=0)\n",
    "# Dataset = pd.DataFrame(Dataset, columns=column_names)\n",
    "# Dataset['user-id'] = dataset['user-id']\n",
    "# Dataset['timestamp'] = dataset['timestamp']\n",
    "# Dataset['activity'] = dataset['activity']\n",
    "# print(Dataset)\n",
    "# label = dataset['activity']\n",
    "# user = dataset['user-id']\n",
    "# timestamp = dataset['timestamp']\n",
    "# dataset = dataset.drop(columns=['activity','user-id','timestamp'])\n",
    "# dataset = feature_selection_pearson(dataset,0.99)\n",
    "# dataset['activity'] = label\n",
    "# dataset['user-id'] = user\n",
    "# dataset['timestamp'] = timestamp\n",
    "# print(dataset)\n",
    "test, train = split_test_train(dataset, 'user-id', 0.8)\n",
    "# print(test.shape)\n",
    "# print(train.columns.difference(['activity','user-id','timestamp']))\n",
    "x_train, y_train = segment(train, TIME_PERIODS, STEP_DISTANCE, 'activity', train.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "x_test, y_test = segment(test, TIME_PERIODS, STEP_DISTANCE, 'activity', test.columns.difference(['activity','user-id','timestamp']), 'user-id')\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)\n",
    "# print(x_test)\n",
    "x_test_n = change_segments(x_test)\n",
    "x_train_n = change_segments(x_train)\n",
    "# x_train_n_columns = feature_selection_pearson(pd.Dataframe(x_train_n), 0.9)\n",
    "# print(x_test_n)\n",
    "# print(x_train)\n",
    "# print(x_test_n.shape, ',', y_test.shape)\n",
    "# print(x_train_n.shape, ',', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     2     3     4     7     8          10         11        12  \\\n",
      "0      15.0   6.0   2.0   5.0  39.0  28.0   8.884487   6.000000  7.174556   \n",
      "1       9.0  38.0  33.0  28.0  14.0   4.0  11.671765  11.125000  3.586754   \n",
      "2       9.0  26.0  40.0  26.0  23.0   6.0   2.329803   9.450000  4.586164   \n",
      "3      12.0  22.0  32.0  37.0  24.0  22.0  11.295586   9.047619  4.226434   \n",
      "4      18.0  17.0  39.0   0.0  19.0  37.0   5.061157   9.700000  8.701770   \n",
      "...     ...   ...   ...   ...   ...   ...        ...        ...       ...   \n",
      "13816   6.0  28.0  54.0  43.0   7.0   3.0  -1.349007   3.545455  0.317351   \n",
      "13817   2.0  10.0  12.0  31.0  14.0   8.0  -1.354288   3.803922  0.503923   \n",
      "13818   3.0   7.0   8.0  24.0  33.0   9.0  -1.251841   4.083333  0.389108   \n",
      "13819   6.0  84.0  35.0   4.0   0.0   0.0  -1.107864   3.840000  0.395505   \n",
      "13820   2.0  28.0  61.0  61.0   7.0   0.0  -1.243063   4.595238  0.500671   \n",
      "\n",
      "             13  ...    72    73    75    76    77    79        80         81  \\\n",
      "0      5.721865  ...  17.0  21.0  40.0  14.0  22.0  12.0 -0.037187   7.791667   \n",
      "1      2.901235  ...  31.0  22.0  30.0  10.0   4.0   7.0  0.415082  14.272727   \n",
      "2      3.839074  ...   3.0   4.0  19.0  71.0  31.0  28.0 -0.287333  24.714286   \n",
      "3      3.521195  ...  11.0  29.0   7.0  12.0  26.0  16.0 -0.845478  44.333333   \n",
      "4      8.074134  ...  14.0  47.0  11.0   6.0   1.0   1.0 -1.429424  21.000000   \n",
      "...         ...  ...   ...   ...   ...   ...   ...   ...       ...        ...   \n",
      "13816  0.242926  ...  15.0  60.0  28.0   1.0   1.0   1.0 -0.007409   5.051282   \n",
      "13817  0.371143  ...  10.0  22.0  52.0  31.0  15.0   6.0 -0.003707   5.305556   \n",
      "13818  0.283254  ...  42.0  77.0  13.0   5.0   1.0   2.0 -0.005444   5.735294   \n",
      "13819  0.280659  ...   2.0  10.0  91.0  13.0   7.0   4.0 -0.008538   4.794872   \n",
      "13820  0.373741  ...  17.0  24.0  39.0  30.0  19.0   8.0  0.002386   5.878788   \n",
      "\n",
      "             82        83  \n",
      "0      3.076522  2.476975  \n",
      "1      2.590268  2.156908  \n",
      "2      3.239990  2.244022  \n",
      "3      4.471496  4.021077  \n",
      "4      2.474327  2.036277  \n",
      "...         ...       ...  \n",
      "13816  0.029260  0.021146  \n",
      "13817  0.045412  0.034223  \n",
      "13818  0.054724  0.039156  \n",
      "13819  0.047426  0.030462  \n",
      "13820  0.054062  0.043008  \n",
      "\n",
      "[13821 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(pd.DataFrame(x_train_n))\n",
    "x_train_n_1 = pd.DataFrame(x_train_n)\n",
    "# print(x_train_n_1)\n",
    "x_test_n_1 = pd.DataFrame(x_test_n)\n",
    "# remove_columns = feature_selection_pearson(x_train_n_1, 0.9) #0.9 thresh, 78 columns\n",
    "remove_columns = p_value(x_train_n_1, y_train, 0.05) #0.1 thresh, 69 columns - 0.05, 64 columns\n",
    "x_train_n_1 = x_train_n_1.drop(columns=remove_columns)\n",
    "x_test_n_1 = x_test_n_1.drop(columns=remove_columns)\n",
    "print(x_train_n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2113 -0.5027 -0.7933 ... 0.8095 1.5447 1.8329]\n",
      " [-0.1587 -0.7875 -0.4980 ... 0.6397 1.9874 2.1346]\n",
      " [-0.3691 -0.8825 -0.7511 ... 0.8095 1.8949 2.1050]\n",
      " ...\n",
      " [-0.5795 0.2095 -0.2027 ... -0.2817 0.3975 0.2079]\n",
      " [-0.0535 -0.6451 -0.2871 ... -0.2232 0.2345 0.1479]\n",
      " [0.6302 -0.3128 -0.5824 ... -0.2276 0.7700 0.4169]]\n"
     ]
    }
   ],
   "source": [
    "# transformer = Normalizer().fit(x_train_n_1) # pearson 0.9, acc 0.42\n",
    "transformer = StandardScaler().fit(x_train_n_1) # pearson 0.9, acc 0.69; p-value 0.1, acc 0.69\n",
    "# transformer = preprocessing.MinMaxScaler().fit(x_train_n_1) # pearson 0.9, acc 0.65; p-value 0.05, acc 0.64\n",
    "x_train_n = transformer.transform(x_train_n_1)\n",
    "x_test_n = transformer.transform(x_test_n_1)\n",
    "with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):\n",
    "    print(x_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weight option: balanced\n",
      "Best kernel: rbf\n",
      "Best polynomial degree: 2\n",
      "Best gamma: auto_deprecated\n",
      "Best C: 1.0\n",
      "Best tolerance: 0.001\n",
      "Best max number of iterations -1\n",
      "Best decision function shape option ovr \n",
      "\n",
      "The accuracy score is:  0.6898966322107369\n",
      "The balanced accuracy score is:  0.6944319354389848\n"
     ]
    }
   ],
   "source": [
    "param_grid_in = [\n",
    "#             {'C': [0.01, 0.001, 0.0001],\n",
    "#              'tol': [1, 0.01, 0.001, 0.0001],\n",
    "#              'max_iter': [-1, 1000, 5000],\n",
    "             {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'degree': [2], # ,3\n",
    "             'class_weight': ['balanced']}\n",
    "#              'gamma': [1, 0.1, 0.001, 0.0001, 0.00001],\n",
    "#              'decision_function_shape': ['ovo', 'ovr'],  # one-vs-one/one-vs-rest\n",
    "#              'class_weight': ['balanced']}  # auto balance the weight\n",
    "        ]\n",
    "clf = SVC()\n",
    "svm_model = GridSearchCV(clf, param_grid=param_grid_in, cv=10, n_jobs=4, error_score=np.nan, verbose=0) \n",
    "svm_model = svm_model.fit(x_train_n, y_train)\n",
    "# train the model and time the training\n",
    "#     start_time = time.time()\n",
    "#     svm_model = svm_model.fit(x_train_in, y_train_in)\n",
    "#     end_time = time.time()\n",
    "\n",
    "# print time for training\n",
    "# print('\\nTraining takes ', end_time - start_time, 's\\n')\n",
    "\n",
    "# print the best hyper-parameters\n",
    "print('\\nClass weight option:', svm_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best kernel:', svm_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best polynomial degree:', svm_model.best_estimator_.get_params()['degree'])\n",
    "print('Best gamma:', svm_model.best_estimator_.get_params()['gamma'])\n",
    "print('Best C:', svm_model.best_estimator_.get_params()['C'])\n",
    "print('Best tolerance:', svm_model.best_estimator_.get_params()['tol'])\n",
    "print('Best max number of iterations', svm_model.best_estimator_.get_params()['max_iter'])\n",
    "print('Best decision function shape option', svm_model.best_estimator_.get_params()['decision_function_shape'],\n",
    "      '\\n')\n",
    "\n",
    "# print the accuracy scores\n",
    "y_pred = svm_model.predict(x_test_n)\n",
    "result = metrics.accuracy_score(y_test, y_pred)\n",
    "result_2 = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "print('The accuracy score is: ', result)\n",
    "print('The balanced accuracy score is: ', result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
